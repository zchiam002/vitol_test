1. Create a data loader, make a class so that the main category, title and content can be distinguished easily
2. Let's preprocess the data 
3. 



Process Search String: The user's search string would be converted into a vector representation using the same method as the articles (e.g., TF-IDF or BERT embeddings).

it is important to talk about chunking 
it is important to make a mention about BERT and so on
it is important to talk about RAG and graph importance also 
how do i search the database then?


    # 1. Generate embedding for the search query
    # 2. Compute relevance (cosine similarity) for all articles
    # 3. Load pre-computed topic, novelty, and key_terms for each article
    # 4. Create a list of result dictionaries with {'topic', 'relevance', 'novelty', 'article', 'key_terms'}
    # 5. Sort the list based on the 'sort_by' parameter
    # 6. Return the top N results

    pgvector 